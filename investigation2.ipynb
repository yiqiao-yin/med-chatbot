{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to extract text from pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "def extract_pdf_text(filepath: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts text from each page of a PDF file using PyPDF2 and returns it as a list of strings.\n",
    "    \n",
    "    Parameters:\n",
    "    filepath (str): The file path or URL of the PDF file to extract text from.\n",
    "    \n",
    "    Returns:\n",
    "    List[str]: A list of strings containing the extracted text from each page of the PDF.\n",
    "    \"\"\"\n",
    "    pdf_file = open(filepath, 'rb')\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "    pages = len(pdf_reader.pages)\n",
    "\n",
    "    text_list = []\n",
    "    for page in range(pages):\n",
    "        pdf_page = pdf_reader.pages[page]\n",
    "        text = pdf_page.extract_text()\n",
    "        text_list.append(text)\n",
    "        \n",
    "    pdf_file.close()\n",
    "    return text_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pdf_text_list = extract_pdf_text('2022.pdf')\n",
    "print(pdf_text_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_text_list[5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create question-answer dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"ENTER YOUR API KEY HERE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pdf_text_list)\n",
    "df.columns = ['context']\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes in a single argument `context`, which is a string representing the context for which questions should be generated. It returns a string containing the question generated by the API.\n",
    "\n",
    "The function uses `try` and `except` to catch any errors that might occur while interacting with the API. It sends a POST request to the OpenAI Completion API using the `openai.Completion.create()` method, passing in various parameters such as the GPT-3 engine to use, the prompt to use (which includes the context and a placeholder for the question), and settings for temperature, max tokens, and penalties.\n",
    "\n",
    "If the request is successful, the function extracts the question text from the response dictionary and returns it. If there was an error, the function returns an empty string.\n",
    "\n",
    "The function has type hints for both arguments and return value, and includes a docstring that describes what the function does, what arguments it takes, and what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(context: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a text context, generates a list of questions using OpenAI's GPT-3 API.\n",
    "\n",
    "    Args:\n",
    "    - context: A string representing the context for which questions should be generated.\n",
    "\n",
    "    Returns:\n",
    "    - A string containing the question generated by the API.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"davinci-instruct-beta-v3\",\n",
    "            prompt=f\"Write questions based on the text below\\n\\nText: {context}\\n\\nQuestions:\\n1.\",\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=[\"\\n\\n\"]\n",
    "        )\n",
    "        # Extract question text from the response\n",
    "        question_text = response['choices'][0]['text']\n",
    "        return question_text\n",
    "    except:\n",
    "        # Return an empty string if there was an error\n",
    "        return \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['questions']= df.context.apply(get_questions)\n",
    "df['questions'] = \"1.\" + df.questions\n",
    "print(df[['questions']].values[0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes in a single argument `row`, which is a pandas dataframe row containing 'context' and 'questions' columns. It returns a string containing the answer generated by the API.\n",
    "\n",
    "The function uses `try` and `except` to catch any errors that might occur while interacting with the API. It sends a POST request to the OpenAI Completion API using the `openai.Completion.create()` method, passing in various parameters such as the GPT-3 engine to use, the prompt to use (which includes the context, the question, and a placeholder for the answer), and settings for temperature, max tokens, and penalties.\n",
    "\n",
    "If the request is successful, the function extracts the answer text from the response dictionary and returns it. If there was an error, the function prints the error message and returns an empty string.\n",
    "\n",
    "The function has type hints for both arguments and return value, and includes a docstring that describes what the function does, what arguments it takes, and what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(row: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Given a dataframe row containing context and questions, generates an answer using OpenAI's GPT-3 API.\n",
    "\n",
    "    Args:\n",
    "    - row: A pandas dataframe row containing 'context' and 'questions' columns.\n",
    "\n",
    "    Returns:\n",
    "    - A string containing the answer generated by the API.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"davinci-instruct-beta-v3\",\n",
    "            prompt=f\"Write answer (limit to 1 paragraph) based on the text below\\n\\nText: {row.context}\\n\\nQuestions:\\n{row.questions}\\n\\nAnswers:\\n1.\",\n",
    "            temperature=0,\n",
    "            max_tokens=800,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "        # Extract answer text from the response\n",
    "        answer_text = response['choices'][0]['text']\n",
    "        return answer_text\n",
    "    except Exception as e:\n",
    "        # Print the error message and return an empty string if there was an error\n",
    "        print (e)\n",
    "        return \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['answers']= df.apply(get_answers, axis=1)\n",
    "df['answers'] = \"1.\" + df.answers\n",
    "df = df.dropna().reset_index().drop('index',axis=1)\n",
    "print(df[['answers']].values[0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tmp_output_ar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_jon_py39_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
